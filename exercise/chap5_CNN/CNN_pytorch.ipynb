{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syJBjQcvXDBg",
        "outputId": "fda7808a-e8b1-422b-9edd-7d085443b70a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 34.8MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.19MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 10.5MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.59MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/datasets/mnist.py:81: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n",
            "<ipython-input-1-dddd7fb1d9d9>:24: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  test_x = Variable(torch.unsqueeze(test_data.test_data, dim=1), volatile=True).type(torch.FloatTensor)[:500]/255.\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/datasets/mnist.py:71: UserWarning: test_labels has been renamed targets\n",
            "  warnings.warn(\"test_labels has been renamed targets\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========== 20 ===== ===== test accuracy is 0.25 ==========\n",
            "========== 40 ===== ===== test accuracy is 0.27 ==========\n",
            "========== 60 ===== ===== test accuracy is 0.412 ==========\n",
            "========== 80 ===== ===== test accuracy is 0.61 ==========\n",
            "========== 100 ===== ===== test accuracy is 0.596 ==========\n",
            "========== 120 ===== ===== test accuracy is 0.662 ==========\n",
            "========== 140 ===== ===== test accuracy is 0.68 ==========\n",
            "========== 160 ===== ===== test accuracy is 0.712 ==========\n",
            "========== 180 ===== ===== test accuracy is 0.762 ==========\n",
            "========== 200 ===== ===== test accuracy is 0.78 ==========\n",
            "========== 220 ===== ===== test accuracy is 0.814 ==========\n",
            "========== 240 ===== ===== test accuracy is 0.842 ==========\n",
            "========== 260 ===== ===== test accuracy is 0.84 ==========\n",
            "========== 280 ===== ===== test accuracy is 0.836 ==========\n",
            "========== 300 ===== ===== test accuracy is 0.856 ==========\n",
            "========== 320 ===== ===== test accuracy is 0.872 ==========\n",
            "========== 340 ===== ===== test accuracy is 0.89 ==========\n",
            "========== 360 ===== ===== test accuracy is 0.874 ==========\n",
            "========== 380 ===== ===== test accuracy is 0.89 ==========\n",
            "========== 400 ===== ===== test accuracy is 0.874 ==========\n",
            "========== 420 ===== ===== test accuracy is 0.902 ==========\n",
            "========== 440 ===== ===== test accuracy is 0.876 ==========\n",
            "========== 460 ===== ===== test accuracy is 0.904 ==========\n",
            "========== 480 ===== ===== test accuracy is 0.908 ==========\n",
            "========== 500 ===== ===== test accuracy is 0.898 ==========\n",
            "========== 520 ===== ===== test accuracy is 0.906 ==========\n",
            "========== 540 ===== ===== test accuracy is 0.918 ==========\n",
            "========== 560 ===== ===== test accuracy is 0.902 ==========\n",
            "========== 580 ===== ===== test accuracy is 0.91 ==========\n",
            "========== 600 ===== ===== test accuracy is 0.912 ==========\n",
            "========== 620 ===== ===== test accuracy is 0.916 ==========\n",
            "========== 640 ===== ===== test accuracy is 0.908 ==========\n",
            "========== 660 ===== ===== test accuracy is 0.914 ==========\n",
            "========== 680 ===== ===== test accuracy is 0.922 ==========\n",
            "========== 700 ===== ===== test accuracy is 0.914 ==========\n",
            "========== 720 ===== ===== test accuracy is 0.926 ==========\n",
            "========== 740 ===== ===== test accuracy is 0.922 ==========\n",
            "========== 760 ===== ===== test accuracy is 0.926 ==========\n",
            "========== 780 ===== ===== test accuracy is 0.936 ==========\n",
            "========== 800 ===== ===== test accuracy is 0.948 ==========\n",
            "========== 820 ===== ===== test accuracy is 0.926 ==========\n",
            "========== 840 ===== ===== test accuracy is 0.936 ==========\n",
            "========== 860 ===== ===== test accuracy is 0.938 ==========\n",
            "========== 880 ===== ===== test accuracy is 0.938 ==========\n",
            "========== 900 ===== ===== test accuracy is 0.944 ==========\n",
            "========== 920 ===== ===== test accuracy is 0.932 ==========\n",
            "========== 940 ===== ===== test accuracy is 0.936 ==========\n",
            "========== 960 ===== ===== test accuracy is 0.936 ==========\n",
            "========== 980 ===== ===== test accuracy is 0.954 ==========\n",
            "========== 1000 ===== ===== test accuracy is 0.94 ==========\n",
            "========== 1020 ===== ===== test accuracy is 0.958 ==========\n",
            "========== 1040 ===== ===== test accuracy is 0.944 ==========\n",
            "========== 1060 ===== ===== test accuracy is 0.944 ==========\n",
            "========== 1080 ===== ===== test accuracy is 0.95 ==========\n",
            "========== 1100 ===== ===== test accuracy is 0.946 ==========\n",
            "========== 1120 ===== ===== test accuracy is 0.956 ==========\n",
            "========== 1140 ===== ===== test accuracy is 0.96 ==========\n",
            "========== 1160 ===== ===== test accuracy is 0.958 ==========\n",
            "========== 1180 ===== ===== test accuracy is 0.956 ==========\n",
            "========== 20 ===== ===== test accuracy is 0.952 ==========\n",
            "========== 40 ===== ===== test accuracy is 0.948 ==========\n",
            "========== 60 ===== ===== test accuracy is 0.956 ==========\n",
            "========== 80 ===== ===== test accuracy is 0.952 ==========\n",
            "========== 100 ===== ===== test accuracy is 0.946 ==========\n",
            "========== 120 ===== ===== test accuracy is 0.954 ==========\n",
            "========== 140 ===== ===== test accuracy is 0.956 ==========\n",
            "========== 160 ===== ===== test accuracy is 0.95 ==========\n",
            "========== 180 ===== ===== test accuracy is 0.942 ==========\n",
            "========== 200 ===== ===== test accuracy is 0.964 ==========\n",
            "========== 220 ===== ===== test accuracy is 0.95 ==========\n",
            "========== 240 ===== ===== test accuracy is 0.954 ==========\n",
            "========== 260 ===== ===== test accuracy is 0.954 ==========\n",
            "========== 280 ===== ===== test accuracy is 0.944 ==========\n",
            "========== 300 ===== ===== test accuracy is 0.95 ==========\n",
            "========== 320 ===== ===== test accuracy is 0.95 ==========\n",
            "========== 340 ===== ===== test accuracy is 0.964 ==========\n",
            "========== 360 ===== ===== test accuracy is 0.958 ==========\n",
            "========== 380 ===== ===== test accuracy is 0.966 ==========\n",
            "========== 400 ===== ===== test accuracy is 0.964 ==========\n",
            "========== 420 ===== ===== test accuracy is 0.962 ==========\n",
            "========== 440 ===== ===== test accuracy is 0.964 ==========\n",
            "========== 460 ===== ===== test accuracy is 0.962 ==========\n",
            "========== 480 ===== ===== test accuracy is 0.968 ==========\n",
            "========== 500 ===== ===== test accuracy is 0.968 ==========\n",
            "========== 520 ===== ===== test accuracy is 0.964 ==========\n",
            "========== 540 ===== ===== test accuracy is 0.964 ==========\n",
            "========== 560 ===== ===== test accuracy is 0.954 ==========\n",
            "========== 580 ===== ===== test accuracy is 0.956 ==========\n",
            "========== 600 ===== ===== test accuracy is 0.962 ==========\n",
            "========== 620 ===== ===== test accuracy is 0.96 ==========\n",
            "========== 640 ===== ===== test accuracy is 0.97 ==========\n",
            "========== 660 ===== ===== test accuracy is 0.968 ==========\n",
            "========== 680 ===== ===== test accuracy is 0.96 ==========\n",
            "========== 700 ===== ===== test accuracy is 0.964 ==========\n",
            "========== 720 ===== ===== test accuracy is 0.968 ==========\n",
            "========== 740 ===== ===== test accuracy is 0.962 ==========\n",
            "========== 760 ===== ===== test accuracy is 0.962 ==========\n",
            "========== 780 ===== ===== test accuracy is 0.966 ==========\n",
            "========== 800 ===== ===== test accuracy is 0.968 ==========\n",
            "========== 820 ===== ===== test accuracy is 0.962 ==========\n",
            "========== 840 ===== ===== test accuracy is 0.97 ==========\n",
            "========== 860 ===== ===== test accuracy is 0.968 ==========\n",
            "========== 880 ===== ===== test accuracy is 0.966 ==========\n",
            "========== 900 ===== ===== test accuracy is 0.968 ==========\n",
            "========== 920 ===== ===== test accuracy is 0.962 ==========\n",
            "========== 940 ===== ===== test accuracy is 0.962 ==========\n",
            "========== 960 ===== ===== test accuracy is 0.968 ==========\n",
            "========== 980 ===== ===== test accuracy is 0.964 ==========\n",
            "========== 1000 ===== ===== test accuracy is 0.976 ==========\n",
            "========== 1020 ===== ===== test accuracy is 0.962 ==========\n",
            "========== 1040 ===== ===== test accuracy is 0.97 ==========\n",
            "========== 1060 ===== ===== test accuracy is 0.97 ==========\n",
            "========== 1080 ===== ===== test accuracy is 0.966 ==========\n",
            "========== 1100 ===== ===== test accuracy is 0.966 ==========\n",
            "========== 1120 ===== ===== test accuracy is 0.968 ==========\n",
            "========== 1140 ===== ===== test accuracy is 0.966 ==========\n",
            "========== 1160 ===== ===== test accuracy is 0.962 ==========\n",
            "========== 1180 ===== ===== test accuracy is 0.97 ==========\n",
            "========== 20 ===== ===== test accuracy is 0.962 ==========\n",
            "========== 40 ===== ===== test accuracy is 0.97 ==========\n",
            "========== 60 ===== ===== test accuracy is 0.97 ==========\n",
            "========== 80 ===== ===== test accuracy is 0.97 ==========\n",
            "========== 100 ===== ===== test accuracy is 0.974 ==========\n",
            "========== 120 ===== ===== test accuracy is 0.968 ==========\n",
            "========== 140 ===== ===== test accuracy is 0.956 ==========\n",
            "========== 160 ===== ===== test accuracy is 0.97 ==========\n",
            "========== 180 ===== ===== test accuracy is 0.964 ==========\n",
            "========== 200 ===== ===== test accuracy is 0.966 ==========\n",
            "========== 220 ===== ===== test accuracy is 0.974 ==========\n",
            "========== 240 ===== ===== test accuracy is 0.978 ==========\n",
            "========== 260 ===== ===== test accuracy is 0.97 ==========\n",
            "========== 280 ===== ===== test accuracy is 0.974 ==========\n",
            "========== 300 ===== ===== test accuracy is 0.964 ==========\n",
            "========== 320 ===== ===== test accuracy is 0.964 ==========\n",
            "========== 340 ===== ===== test accuracy is 0.972 ==========\n",
            "========== 360 ===== ===== test accuracy is 0.964 ==========\n",
            "========== 380 ===== ===== test accuracy is 0.98 ==========\n",
            "========== 400 ===== ===== test accuracy is 0.974 ==========\n",
            "========== 420 ===== ===== test accuracy is 0.976 ==========\n",
            "========== 440 ===== ===== test accuracy is 0.964 ==========\n",
            "========== 460 ===== ===== test accuracy is 0.98 ==========\n",
            "========== 480 ===== ===== test accuracy is 0.974 ==========\n",
            "========== 500 ===== ===== test accuracy is 0.974 ==========\n",
            "========== 520 ===== ===== test accuracy is 0.972 ==========\n",
            "========== 540 ===== ===== test accuracy is 0.974 ==========\n",
            "========== 560 ===== ===== test accuracy is 0.982 ==========\n",
            "========== 580 ===== ===== test accuracy is 0.974 ==========\n",
            "========== 600 ===== ===== test accuracy is 0.968 ==========\n",
            "========== 620 ===== ===== test accuracy is 0.976 ==========\n",
            "========== 640 ===== ===== test accuracy is 0.976 ==========\n",
            "========== 660 ===== ===== test accuracy is 0.976 ==========\n",
            "========== 680 ===== ===== test accuracy is 0.982 ==========\n",
            "========== 700 ===== ===== test accuracy is 0.972 ==========\n",
            "========== 720 ===== ===== test accuracy is 0.976 ==========\n",
            "========== 740 ===== ===== test accuracy is 0.972 ==========\n",
            "========== 760 ===== ===== test accuracy is 0.974 ==========\n",
            "========== 780 ===== ===== test accuracy is 0.978 ==========\n",
            "========== 800 ===== ===== test accuracy is 0.984 ==========\n",
            "========== 820 ===== ===== test accuracy is 0.968 ==========\n",
            "========== 840 ===== ===== test accuracy is 0.976 ==========\n",
            "========== 860 ===== ===== test accuracy is 0.974 ==========\n",
            "========== 880 ===== ===== test accuracy is 0.976 ==========\n",
            "========== 900 ===== ===== test accuracy is 0.974 ==========\n",
            "========== 920 ===== ===== test accuracy is 0.972 ==========\n",
            "========== 940 ===== ===== test accuracy is 0.958 ==========\n",
            "========== 960 ===== ===== test accuracy is 0.978 ==========\n",
            "========== 980 ===== ===== test accuracy is 0.978 ==========\n",
            "========== 1000 ===== ===== test accuracy is 0.974 ==========\n",
            "========== 1020 ===== ===== test accuracy is 0.978 ==========\n",
            "========== 1040 ===== ===== test accuracy is 0.976 ==========\n",
            "========== 1060 ===== ===== test accuracy is 0.97 ==========\n",
            "========== 1080 ===== ===== test accuracy is 0.978 ==========\n",
            "========== 1100 ===== ===== test accuracy is 0.98 ==========\n",
            "========== 1120 ===== ===== test accuracy is 0.978 ==========\n",
            "========== 1140 ===== ===== test accuracy is 0.976 ==========\n",
            "========== 1160 ===== ===== test accuracy is 0.974 ==========\n",
            "========== 1180 ===== ===== test accuracy is 0.986 ==========\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.utils.data as Data\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "learning_rate = 1e-4\n",
        "keep_prob_rate = 0.7\n",
        "max_epoch = 3\n",
        "BATCH_SIZE = 50\n",
        "\n",
        "DOWNLOAD_MNIST = False\n",
        "if not(os.path.exists('./mnist/')) or not os.listdir('./mnist/'):\n",
        "    # not mnist dir or mnist is empyt dir\n",
        "    DOWNLOAD_MNIST = True\n",
        "\n",
        "train_data = torchvision.datasets.MNIST(root='./mnist/', train=True, transform=torchvision.transforms.ToTensor(), download=DOWNLOAD_MNIST)\n",
        "train_loader = Data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "test_data = torchvision.datasets.MNIST(root='./mnist/', train=False)\n",
        "test_x = Variable(torch.unsqueeze(test_data.test_data, dim=1), volatile=True).type(torch.FloatTensor)[:500]/255.\n",
        "test_y = test_data.test_labels[:500].numpy()\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=1,  # MNIST images are grayscale, so only 1 channel\n",
        "                out_channels=32,  # Number of output channels\n",
        "                kernel_size=7,  # 7x7 kernel\n",
        "                stride=1,  # Stride of 1\n",
        "                padding=3,  # Padding to keep the same size (same padding)\n",
        "            ),\n",
        "            nn.ReLU(),  # Activation function\n",
        "            nn.MaxPool2d(2),  # 2x2 pooling\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=32,  # Input channels from the previous layer\n",
        "                out_channels=64,  # Number of output channels\n",
        "                kernel_size=5,  # 5x5 kernel\n",
        "                stride=1,  # Stride of 1\n",
        "                padding=2,  # Padding to keep the same size (same padding)\n",
        "            ),\n",
        "            nn.ReLU(),  # Activation function\n",
        "            nn.MaxPool2d(2),  # 2x2 pooling\n",
        "        )\n",
        "        self.out1 = nn.Linear(7*7*64, 1024, bias=True)  # Fully connected layer\n",
        "        self.dropout = nn.Dropout(keep_prob_rate)\n",
        "        self.out2 = nn.Linear(1024, 10, bias=True)  # Output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten the output for the fully connected layer\n",
        "        out1 = self.out1(x)\n",
        "        out1 = F.relu(out1)\n",
        "        out1 = self.dropout(out1)\n",
        "        out2 = self.out2(out1)\n",
        "        output = F.softmax(out2, dim=1)  # Softmax for classification\n",
        "        return output\n",
        "\n",
        "def test(cnn):\n",
        "    global prediction\n",
        "    y_pre = cnn(test_x)\n",
        "    _, pre_index = torch.max(y_pre, 1)\n",
        "    pre_index = pre_index.view(-1)\n",
        "    prediction = pre_index.data.numpy()\n",
        "    correct = np.sum(prediction == test_y)\n",
        "    return correct / 500.0\n",
        "\n",
        "def train(cnn):\n",
        "    optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate)\n",
        "    loss_func = nn.CrossEntropyLoss()\n",
        "    for epoch in range(max_epoch):\n",
        "        for step, (x_, y_) in enumerate(train_loader):\n",
        "            x, y = Variable(x_), Variable(y_)\n",
        "            output = cnn(x)\n",
        "            loss = loss_func(output, y)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if step != 0 and step % 20 == 0:\n",
        "                print(\"=\" * 10, step, \"=\" * 5, \"=\" * 5, \"test accuracy is\", test(cnn), \"=\" * 10)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    cnn = CNN()\n",
        "    train(cnn)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "87sSybBGXYIq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python [default]",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}